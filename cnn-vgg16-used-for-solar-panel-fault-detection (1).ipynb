{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;background-color:#e90045;padding:3%;border-radius:150px 150px;font-size:3em;text-align:center\">Solar Panel Image Classification using VGG16</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Objective of this project](#1)\n",
    "* [Factors that can cause a reduction in power generation from solar panels](#2)\n",
    "* [Effects of dirt, debris, snow, bird drop and electrical damage on solar panels health](#3)\n",
    "* [Deep learning & Solar Panel fault classification](#4)\n",
    "* [About Dataset](#5)\n",
    "    * [VGG16](#6)\n",
    "    * [Transfer learning & VGG16](#7)\n",
    "    * [VGG16 and its limitations](#8)\n",
    "    * [Ways to overcome the limitations of VGG16](#9)\n",
    "    * [Result Classification](#10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://wallpapercave.com/wp/wp4041905.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">Objective of this project ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accumulation of dust, snow, bird drops etc. on the surface of solar panels reduces the efficiency of the solar modules and hence the amount of produced energy. Monitoring and cleaning solar panels is a crucial task, hence developing an optimal procedure to monitor and clean these panels is very important in order to increase modules efficiency, reduce maintenance cost and reducing the use of resources.**\n",
    "\n",
    "**The objective of this project is to investigate the ability of different machine learning classifiers to detect dust, snow, bird drops, physical and electrical on solar panel surfaces with the highest possible accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:20px; color:#FBFAFC; \">Factors that can cause a reduction in power generation from solar panels ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsSz8o9jFXlW",
    "outputId": "251c30fc-0b36-41ae-9e8b-b4c8161e85ec"
   },
   "source": [
    "<font color='Red'>\n",
    "\n",
    "**There are a number of factors that can cause a reduction in power generation from solar panels. These include:**\n",
    "\n",
    "<font color='Blue'>   \n",
    "    \n",
    "1. *Reduced sunlight: Solar panels generate electricity by converting sunlight into electricity. If there is less sunlight, then there will be less electricity generated. This can happen on cloudy days, during the winter, or in areas with high levels of air pollution.*\n",
    "    \n",
    "2. *High temperatures: Solar panels are most efficient when they are at a moderate temperature. If the temperature gets too high, then the efficiency of the solar panel will decrease. This is because the heat causes the electrons in the solar cells to move faster, which reduces the amount of energy that is converted into electricity.*\n",
    "    \n",
    "3. *Dirt and debris: Dirt and debris can block sunlight from reaching the solar panel, which will reduce the amount of electricity that is generated. It is important to clean solar panels regularly to remove any dirt or debris that has accumulated.*\n",
    "    \n",
    "4. *Degradation: Solar panels will degrade over time, which will reduce their efficiency. The rate of degradation will vary depending on the type of solar panel and the conditions in which it is installed.*\n",
    "    \n",
    "5. *Inverter failure: The inverter is a device that converts the direct current (DC) electricity generated by the solar panel into alternating current (AC) electricity, which is the type of electricity that is used in homes and businesses. If the inverter fails, then the solar panel will not be able to generate electricity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:20px; color:#FBFAFC; \">Effects of dirt, debris, snow, bird drop and electrical damage on solar panels health ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Red'>\n",
    "    \n",
    "**Here are the effects of dirt, debris, snow, bird drop, mechanical damage and electrical damage on solar panels:**\n",
    "\n",
    "<font color='Blue'>\n",
    "    \n",
    "1. *Dirt and debris: Dirt and debris can block sunlight from reaching the solar panel, which will reduce the amount of electricity that is generated. It is important to clean solar panels regularly to remove any dirt or debris that has accumulated.*\n",
    "    \n",
    "2. *Snow: Snow can also block sunlight from reaching the solar panel, but it will usually melt off on its own during the day. If there is a lot of snow, it may be necessary to remove it manually.*\n",
    "    \n",
    "3. *Bird droppings: Bird droppings can be acidic and can damage the surface of the solar panel. It is important to clean bird droppings off of solar panels as soon as possible.*\n",
    "    \n",
    "3. *Mechanical damage: Solar panels can be damaged by hail, wind, or other objects. If a solar panel is damaged, it will need to be repaired or replaced.*\n",
    "    \n",
    "4. *Electrical damage: Solar panels can be damaged by lightning strikes or other electrical surges. If a solar panel is damaged by electrical damage, it will need to be repaired or replaced.*\n",
    "\n",
    "<font color='Red'>\n",
    "\n",
    "**Here are some tips to help protect solar panels from damage:**\n",
    "\n",
    "<font color='Green'>    \n",
    "    \n",
    "1. *Clean the solar panels regularly. This will help to remove any dirt, debris, or bird droppings that may be blocking sunlight from reaching the panels.*\n",
    "    \n",
    "2. *Install the solar panels in a location that is protected from hail, wind, and other objects. This will help to reduce the risk of mechanical damage.*\n",
    "    \n",
    "3. *Have solar panels inspected by a qualified professional on a regular basis. This will help to identify any potential problems early on and prevent them from causing further damage.*\n",
    "\n",
    "<font color='Red'> \n",
    "    \n",
    "**By following these tips, we can help to keep our solar panels in good condition and maximize their lifespan.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">Deep learning & Solar Panel fault classification ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='Red'>\n",
    "\n",
    "1. **Deep learning can be used to classify different types of faults. This is because deep learning models can learn to distinguish between different types of patterns. For example, a deep learning model could be trained to distinguish between the patterns of a cracked panel, a dirty panel, a burned-out panel, bird dropping on solar panel and snow cover on solar panel.**\n",
    "\n",
    "2. **Deep learning can be used to localize faults. This is because deep learning models can learn to identify the location of a fault within a solar panel. For example, a deep learning model could be trained to identify the location of a cracked panel within a solar plant.**\n",
    "\n",
    "4. **Deep learning is a powerful tool that can be used to improve the efficiency and reliability of solar panel systems. By identifying and localizing faults early on, deep learning can help to prevent costly repairs and downtime.**\n",
    "\n",
    "<font color='Green'> \n",
    "    \n",
    "**Here are some of the benefits of using deep learning for solar panel fault detection:**\n",
    "\n",
    "1. **Accuracy: Deep learning models can achieve high accuracy in detecting faults, even in cases where human inspectors may miss them.**\n",
    "\n",
    "2. **Speed: Deep learning models can quickly scan large amounts of data to identify potential faults.**\n",
    "\n",
    "3. **Scalability: Deep learning models can be easily scaled to handle larger and more complex datasets.**\n",
    "\n",
    "4. **Cost-effectiveness: Deep learning models can be used to automate the fault detection process, which can save money on labor costs.**\n",
    "\n",
    "<font color='Brown'>    \n",
    "    \n",
    "**Overall, deep learning is a promising technology that has the potential to revolutionize solar panel fault detection. By automating the process and improving accuracy, deep learning can help to improve the efficiency and reliability of solar panel systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">About Dataset ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This directory contains six different class folders to classify between. Since the images were scraped from the internet, there is a slight imbalance in the number of images collected.**\n",
    "\n",
    "\n",
    "<font color='Brown'>   \n",
    "    \n",
    "\n",
    "1. Clean: This directory has images of clean solar panels\n",
    "2. Dusty: This directory has images of dusty solar panels\n",
    "3. Bird-drop: This directory has images of bird-drop on solar panels\n",
    "\n",
    "4. Electrical-damage: This directory has images of electrical-damage solar panels\n",
    "\n",
    "5. Physical-Damage: This directory has images of physical-damage solar panels\n",
    "\n",
    "6. Snow-Covered: This directory has images of snow-covered on solar panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:13:37.291333Z",
     "iopub.status.busy": "2023-06-05T22:13:37.290367Z",
     "iopub.status.idle": "2023-06-05T22:13:37.300194Z",
     "shell.execute_reply": "2023-06-05T22:13:37.299050Z",
     "shell.execute_reply.started": "2023-06-05T22:13:37.291280Z"
    },
    "id": "QNTT3WfuAXte"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from cv2 import resize\n",
    "from glob import glob\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:15:25.614232Z",
     "iopub.status.busy": "2023-06-05T22:15:25.613244Z",
     "iopub.status.idle": "2023-06-05T22:15:32.581941Z",
     "shell.execute_reply": "2023-06-05T22:15:32.580842Z",
     "shell.execute_reply.started": "2023-06-05T22:15:25.614190Z"
    },
    "id": "1RZ_DQqF_MTd"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory /kaggle/input/solar-panel-images/Faulty_solar_panel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m244\u001b[39m\n\u001b[0;32m      2\u001b[0m img_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m244\u001b[39m\n\u001b[1;32m----> 3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/solar-panel-images/Faulty_solar_panel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/solar-panel-images/Faulty_solar_panel\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m   validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m   seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     19\u001b[0m   shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\image_dataset.py:210\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 210\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\dataset_utils.py:542\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    544\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:768\u001b[0m, in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(path):\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[0;32m    769\u001b[0m       node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m       op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    771\u001b[0m       message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# Convert each element to string, since the return values of the\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# vector of string should be interpreted as strings, not bytes.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    776\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str_any(filename)\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m _pywrap_file_io\u001b[38;5;241m.\u001b[39mGetChildren(compat\u001b[38;5;241m.\u001b[39mpath_to_bytes(path))\n\u001b[0;32m    778\u001b[0m ]\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory /kaggle/input/solar-panel-images/Faulty_solar_panel"
     ]
    }
   ],
   "source": [
    "img_height = 244\n",
    "img_width = 244\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/kaggle/input/solar-panel-images/Faulty_solar_panel',\n",
    "  validation_split=0.2,\n",
    "  subset='training',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=32,\n",
    "  seed=42,\n",
    "  shuffle=True)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  '/kaggle/input/solar-panel-images/Faulty_solar_panel',\n",
    "  validation_split=0.2,\n",
    "  subset='validation',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=32,\n",
    "  seed=42,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 724 images belonging to 6 classes.\n",
      "Found 132 images belonging to 6 classes.\n",
      "Found 92 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "img_height = 244\n",
    "img_width = 244\n",
    "train_path = r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Train'\n",
    "valid_path = r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Validate'\n",
    "test_path = r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Test'\n",
    "IMAGE_SIZE = [244, 244] #Default image size for VGG16\n",
    "folders = glob(r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Train') #Get number of classes\n",
    "# ImageDataGenerator can help perform augumentation on existing images. This way, we get more diverse train set.\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "#Through flow_from_directory - we create an array of images that can be used for training. \n",
    "train_ds = train_datagen.flow_from_directory(r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Train',\n",
    "                                                 target_size = (244, 244),\n",
    "                                                 batch_size = 4,\n",
    "                                                 class_mode = 'categorical')\n",
    "val_ds = validation_datagen.flow_from_directory(r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Validate',\n",
    "                                                 target_size = (244, 244),\n",
    "                                                 batch_size = 4,\n",
    "                                              class_mode = 'categorical')\n",
    "test_ds = test_datagen.flow_from_directory(r'C:\\Users\\BD537AX\\OneDrive - EY\\Desktop\\New folder\\Test',\n",
    "                                            target_size = (244, 244),\n",
    "                                            batch_size = 4,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:15:39.435997Z",
     "iopub.status.busy": "2023-06-05T22:15:39.435591Z",
     "iopub.status.idle": "2023-06-05T22:15:39.445763Z",
     "shell.execute_reply": "2023-06-05T22:15:39.444545Z",
     "shell.execute_reply.started": "2023-06-05T22:15:39.435966Z"
    },
    "id": "SaOQ_-E--XMO",
    "outputId": "51278ed1-8f37-40f4-f511-3654cfc76a08"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m class_names \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_names\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_names)\n\u001b[0;32m      3\u001b[0m train_ds\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:15:43.012025Z",
     "iopub.status.busy": "2023-06-05T22:15:43.011641Z",
     "iopub.status.idle": "2023-06-05T22:15:50.999796Z",
     "shell.execute_reply": "2023-06-05T22:15:50.998467Z",
     "shell.execute_reply.started": "2023-06-05T22:15:43.011995Z"
    },
    "id": "1R_-ARdq-hZf",
    "outputId": "7971807f-7b2b-46c2-88ef-2a65addc9362"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'take'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m):\n\u001b[0;32m      4\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'take'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(25):\n",
    "        ax = plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">VGG16ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 is a convolutional neural network (CNN) that is widely used for image classification. It was first introduced in 2014 by the Visual Geometry Group (VGG) at the University of Oxford. VGG16 is a deep network, with 16 layers, and it has been shown to be very effective at image classification. It has achieved state-of-the-art results on a number of benchmark datasets, including ImageNet.\n",
    "\n",
    "VGG16 is a popular choice for image classification because it is:\n",
    "\n",
    "1.\tVersatile: VGG16 can be used for a variety of image classification tasks, including object detection, scene classification, and person identification.\n",
    "2.\tAccurate: VGG16 has been shown to be very accurate at image classification, achieving state-of-the-art results on a number of benchmark datasets.\n",
    "3.\tEfficient: VGG16 is relatively efficient, making it a good choice for real-time applications.\n",
    "\n",
    "Here are some of the reasons why we use VGG16:\n",
    "\n",
    "1.\tAccuracy: VGG16 has been shown to be very accurate at image classification, achieving state-of-the-art results on a number of benchmark datasets. For example, on the ImageNet dataset, VGG16 achieves an accuracy of 92.7%.\n",
    "2.\tTransfer learning: VGG16 can be used for transfer learning, which is a technique that allows us to use a pre-trained model to improve the performance of a new model. Transfer learning is often used when we have a small dataset for our new model.\n",
    "3.\tEase of use: VGG16 is available in many deep learning frameworks, such as Keras and TensorFlow. This makes it easy to use for image classification tasks.\n",
    "\n",
    "Overall, VGG16 is a powerful and versatile CNN that is widely used for image classification. It is accurate, efficient, and easy to use.\n",
    "\n",
    "![](https://storage.googleapis.com/lds-media/images/vgg16-architecture.original.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">Transfer learning & VGG16ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning is a machine learning technique where a model trained on one task is reused as the starting point for a model on a second task. This can be useful when there is limited data available for the second task, or when the two tasks are related in some way.\n",
    "\n",
    "VGG16 is a convolutional neural network (CNN) that was trained on the ImageNet dataset, which contains over 14 million images and 1000 different classes. VGG16 is a very powerful model, and it can achieve state-of-the-art results on a variety of image classification tasks.\n",
    "\n",
    "To use transfer learning with VGG16, we can start by loading the pre-trained model from a Keras library. We can then freeze the weights of the first few layers of the model, and train the last few layers on our own dataset. This allows us to take advantage of the knowledge that VGG16 has learned on the ImageNet dataset, while still being able to fine-tune the model to our specific task.\n",
    "\n",
    "Transfer learning with VGG16 can be a very effective way to build a machine learning model when there is limited data available. It can also be used to improve the performance of a model when there is a lot of data available, but the data is noisy or imbalanced.\n",
    "\n",
    "Here are some of the advantages of using transfer learning with VGG16:\n",
    "\n",
    "1.\tReduces the amount of training data required. VGG16 has been trained on a massive dataset, so it already has a good understanding of the general features of images. This means that we can train a model on a smaller dataset, which can save time and resources.\n",
    "2.\tImproves the performance of the model. By fine-tuning the last few layers of VGG16 on our own dataset, we can improve the model's performance on our specific task.\n",
    "3.\tIs relatively easy to implement. There are many tutorials available that show how to use transfer learning with VGG16.\n",
    "\n",
    "Here are some of the disadvantages of using transfer learning with VGG16:\n",
    "\n",
    "4.\tMay not be effective if the data is very different from the data that VGG16 was trained on. If the data is very different from the data that VGG16 was trained on, then transfer learning may not be effective. In this case, it may be better to train a model from scratch.\n",
    "5.\tMay not be able to achieve state-of-the-art results. Transfer learning is a powerful technique, but it may not be able to achieve state-of-the-art results on all tasks. If you need to achieve the best possible results, then you may need to train a model from scratch.\n",
    "\n",
    "Overall, transfer learning with VGG16 is a powerful technique that can be used to build machine learning models when there is limited data available. It can also be used to improve the performance of a model when there is a lot of data available, but the data is noisy or imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.researchgate.net/profile/Amir-Mosavi-3/publication/334992074/figure/fig2/AS:788879695179776@1565094984739/VGG-16-model-Illustration-of-using-the-VGG-16-for-transfer-learning-The-convolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">VGG16 and its limitationsðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 has a number of limitations, including:\n",
    "\n",
    "1.\tComputational complexity: VGG16 is a very computationally expensive model to train and deploy. It has a large number of parameters, which requires a lot of data and computation to train. This can make it difficult to use VGG16 on resource-constrained devices, such as mobile phones or embedded systems.\n",
    "2.\tVanishing gradients: VGG16 is prone to the vanishing gradient problem, which can make it difficult to train the model to convergence. This is because the model has a very deep architecture, which can cause the gradients to become very small as they propagate through the network.\n",
    "3.\tOverfitting: VGG16 is prone to overfitting, which can lead to poor performance on unseen data. This is because the model has a large number of parameters, which can make it difficult to generalize to new data.\n",
    "4.\tData requirements: VGG16 requires a large amount of training data to achieve good performance. This can be a challenge, especially for tasks such as object detection and segmentation, which require a large variety of object classes.\n",
    "\n",
    "**Despite these limitations, VGG16 remains a popular model for image classification tasks. It has achieved state-of-the-art results on a number of benchmark datasets, and it is often used as a baseline for other image classification models. However, it is important to be aware of the limitations of VGG16 when using it for real-world applications.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">Ways to overcome the limitations of VGG16ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the ways to overcome the limitations of VGG16:\n",
    "\n",
    "1.\tData augmentation: Data augmentation can be used to increase the size of the training dataset and reduce overfitting. This can be done by creating new training examples by applying transformations to the existing data, such as cropping, flipping, and rotating images.\n",
    "2.\tRegularization: Regularization techniques can be used to prevent the model from overfitting. This can be done by adding a penalty to the loss function that penalizes the model for having large weights.\n",
    "3.\tTransfer learning: Transfer learning can be used to train a VGG16 model on a smaller dataset. This is done by pre-training the model on a large dataset, such as ImageNet, and then fine-tuning the model on the smaller dataset.\n",
    "\n",
    "**By using these techniques, it is possible to overcome the limitations of VGG16 and achieve good performance on image classification tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:16:13.878964Z",
     "iopub.status.busy": "2023-06-05T22:16:13.878237Z",
     "iopub.status.idle": "2023-06-05T22:16:14.876365Z",
     "shell.execute_reply": "2023-06-05T22:16:14.875264Z",
     "shell.execute_reply.started": "2023-06-05T22:16:13.878927Z"
    },
    "id": "jbyTA_hDF5tL",
    "outputId": "13ead9d9-41e7-489b-87ab-ebb4080afc82"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:16:19.874438Z",
     "iopub.status.busy": "2023-06-05T22:16:19.874044Z",
     "iopub.status.idle": "2023-06-05T22:16:20.004205Z",
     "shell.execute_reply": "2023-06-05T22:16:20.003427Z",
     "shell.execute_reply.started": "2023-06-05T22:16:19.874372Z"
    },
    "id": "CUEDy_7HF5w5",
    "outputId": "e98489dd-2367-430a-a8b5-36477cf5ae30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 244, 244, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_4  (None, 244, 244, 3)       0         \n",
      "  (SlicingOpLambda)                                              \n",
      "                                                                 \n",
      " tf.nn.bias_add_4 (TFOpLamb  (None, 244, 244, 3)       0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_4  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14717766 (56.14 MB)\n",
      "Trainable params: 3078 (12.02 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "outputs = tf.keras.layers.Dense(6)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:16:24.182336Z",
     "iopub.status.busy": "2023-06-05T22:16:24.181254Z",
     "iopub.status.idle": "2023-06-05T22:16:24.484319Z",
     "shell.execute_reply": "2023-06-05T22:16:24.483437Z",
     "shell.execute_reply.started": "2023-06-05T22:16:24.182299Z"
    },
    "id": "lH09ZAZ67W-D",
    "outputId": "6f88fd8f-a217-4dd1-f5aa-a0a2b5738ea3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.utils.vis_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvis_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[0;32m      2\u001b[0m plot_model(model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_plot.png\u001b[39m\u001b[38;5;124m'\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.vis_utils'"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:16:32.086090Z",
     "iopub.status.busy": "2023-06-05T22:16:32.085520Z",
     "iopub.status.idle": "2023-06-05T22:16:47.319477Z",
     "shell.execute_reply": "2023-06-05T22:16:47.318392Z",
     "shell.execute_reply.started": "2023-06-05T22:16:32.086053Z"
    },
    "id": "BbArpl157mS8",
    "outputId": "a46c3016-fd8a-41bb-c6b6-f7dfad0043e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: visualkeras in c:\\users\\bd537ax\\appdata\\roaming\\python\\python39\\site-packages (0.0.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\bd537ax\\appdata\\roaming\\python\\python39\\site-packages (from visualkeras) (1.24.3)\n",
      "Requirement already satisfied: aggdraw>=1.3.11 in c:\\users\\bd537ax\\appdata\\roaming\\python\\python39\\site-packages (from visualkeras) (1.3.16)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\bd537ax\\appdata\\roaming\\python\\python39\\site-packages (from visualkeras) (9.5.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=720x1404>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install visualkeras\n",
    "import visualkeras\n",
    "visualkeras.layered_view(model,legend=True,spacing=50,background_fill = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:17:00.632409Z",
     "iopub.status.busy": "2023-06-05T22:17:00.632032Z",
     "iopub.status.idle": "2023-06-05T22:17:00.647449Z",
     "shell.execute_reply": "2023-06-05T22:17:00.646376Z",
     "shell.execute_reply.started": "2023-06-05T22:17:00.632363Z"
    },
    "id": "sDT5SlL2F5zt"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtFghWmy9WJr"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:17:07.340373Z",
     "iopub.status.busy": "2023-06-05T22:17:07.340030Z",
     "iopub.status.idle": "2023-06-05T22:21:11.541310Z",
     "shell.execute_reply": "2023-06-05T22:21:11.540319Z",
     "shell.execute_reply.started": "2023-06-05T22:17:07.340345Z"
    },
    "id": "ScxkTm5KF52o",
    "outputId": "0b9c6351-be08-4663-e7f0-d64a3c979ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "181/181 [==============================] - 191s 1s/step - loss: 5.4883 - accuracy: 0.2155 - val_loss: 4.9593 - val_accuracy: 0.1591\n",
      "Epoch 2/5\n",
      "181/181 [==============================] - 244s 1s/step - loss: 5.6253 - accuracy: 0.2044 - val_loss: 4.6188 - val_accuracy: 0.1970\n",
      "Epoch 3/5\n",
      "181/181 [==============================] - 226s 1s/step - loss: 5.9911 - accuracy: 0.2265 - val_loss: 4.2611 - val_accuracy: 0.2121\n",
      "Epoch 4/5\n",
      "181/181 [==============================] - 248s 1s/step - loss: 5.8294 - accuracy: 0.2099 - val_loss: 5.5074 - val_accuracy: 0.2197\n",
      "Epoch 5/5\n",
      "181/181 [==============================] - 236s 1s/step - loss: 6.7668 - accuracy: 0.1892 - val_loss: 11.9762 - val_accuracy: 0.2273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2678d00cd90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 5\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:21:13.917873Z",
     "iopub.status.busy": "2023-06-05T22:21:13.917514Z",
     "iopub.status.idle": "2023-06-05T22:21:13.948440Z",
     "shell.execute_reply": "2023-06-05T22:21:13.947625Z",
     "shell.execute_reply.started": "2023-06-05T22:21:13.917847Z"
    },
    "id": "trvvSxxjGQcn",
    "outputId": "65523038-5120-42ad-cff1-6d4ef3d913cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 244, 244, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_4  (None, 244, 244, 3)       0         \n",
      "  (SlicingOpLambda)                                              \n",
      "                                                                 \n",
      " tf.nn.bias_add_4 (TFOpLamb  (None, 244, 244, 3)       0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_4  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14717766 (56.14 MB)\n",
      "Trainable params: 7082502 (27.02 MB)\n",
      "Non-trainable params: 7635264 (29.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:14]:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:22:02.883357Z",
     "iopub.status.busy": "2023-06-05T22:22:02.882975Z",
     "iopub.status.idle": "2023-06-05T22:22:02.898236Z",
     "shell.execute_reply": "2023-06-05T22:22:02.897028Z",
     "shell.execute_reply.started": "2023-06-05T22:22:02.883327Z"
    },
    "id": "EVKWQ_5YGQfv"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:22:10.926537Z",
     "iopub.status.busy": "2023-06-05T22:22:10.926087Z",
     "iopub.status.idle": "2023-06-05T22:24:25.202623Z",
     "shell.execute_reply": "2023-06-05T22:24:25.201406Z",
     "shell.execute_reply.started": "2023-06-05T22:22:10.926501Z"
    },
    "id": "-XcszIeHGQjV",
    "outputId": "9de11822-152f-42ba-b278-abb7bba342e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\BD537AX\\AppData\\Local\\Temp\\ipykernel_32308\\3287488205.py\", line 2, in <module>\n      history = model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [4,6] and labels shape [24]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_40523]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\BD537AX\\AppData\\Local\\Temp\\ipykernel_32308\\3287488205.py\", line 2, in <module>\n      history = model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [4,6] and labels shape [24]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_40523]"
     ]
    }
   ],
   "source": [
    "epoch = 15\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=1e-2,\n",
    "            patience=3,\n",
    "            verbose=1,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:24:36.306047Z",
     "iopub.status.busy": "2023-06-05T22:24:36.305657Z",
     "iopub.status.idle": "2023-06-05T22:24:37.315788Z",
     "shell.execute_reply": "2023-06-05T22:24:37.314694Z",
     "shell.execute_reply.started": "2023-06-05T22:24:36.306018Z"
    },
    "id": "n8UGH01Y9axb",
    "outputId": "bc9351a1-013a-40c4-d4b7-ee3c1854ab41"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ac \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m get_los \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "get_ac = history.history['accuracy']\n",
    "get_los = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(get_ac))\n",
    "plt.plot(epochs, get_ac, 'g', label='Accuracy of Training data')\n",
    "plt.plot(epochs, get_los, 'r', label='Loss of Training data')\n",
    "plt.title('Training data accuracy and loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, get_ac, 'g', label='Accuracy of Training Data')\n",
    "plt.plot(epochs, val_acc, 'r', label='Accuracy of Validation Data')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, get_los, 'g', label='Loss of Training Data')\n",
    "plt.plot(epochs, val_loss, 'r', label='Loss of Validation Data')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> <br>\n",
    "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:12px; font-weight: bold; font-family:Verdana; font-size:28px; color:#FBFAFC; \">Result Classification ðŸ“ŠðŸ“ˆ</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T22:24:44.578254Z",
     "iopub.status.busy": "2023-06-05T22:24:44.577830Z",
     "iopub.status.idle": "2023-06-05T22:25:00.687065Z",
     "shell.execute_reply": "2023-06-05T22:25:00.685883Z",
     "shell.execute_reply.started": "2023-06-05T22:24:44.578227Z"
    },
    "id": "simjZorQ_Be0",
    "outputId": "7496f54c-a3a6-4e55-f6a6-e65c6f359196"
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\BD537AX\\AppData\\Local\\Temp\\ipykernel_32308\\4272033257.py\", line 1, in <module>\n      loss, accuracy = model.evaluate(val_ds)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 2200, in evaluate\n      logs = test_function_runner.run_step(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 4000, in run_step\n      tmp_logs = self._function(dataset_or_iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step\n      outputs = model.test_step(data)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1852, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [4,6] and labels shape [24]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_test_function_27256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m val_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\BD537AX\\AppData\\Local\\Temp\\ipykernel_32308\\4272033257.py\", line 1, in <module>\n      loss, accuracy = model.evaluate(val_ds)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 2200, in evaluate\n      logs = test_function_runner.run_step(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 4000, in run_step\n      tmp_logs = self._function(dataset_or_iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step\n      outputs = model.test_step(data)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1852, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Users\\BD537AX\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [4,6] and labels shape [24]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_test_function_27256]"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(val_ds)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for images, labels in val_ds.take(1):\n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        predictions = model.predict(tf.expand_dims(images[i], 0))\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        if(class_names[labels[i]]==class_names[np.argmax(score)]):\n",
    "            plt.title(\"Actual: \"+class_names[labels[i]])\n",
    "            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'green'})\n",
    "            \n",
    "        else:\n",
    "            plt.title(\"Actual: \"+class_names[labels[i]])\n",
    "            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'red'})\n",
    "        plt.gca().axes.yaxis.set_ticklabels([])        \n",
    "        plt.gca().axes.xaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
